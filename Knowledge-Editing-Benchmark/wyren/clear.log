é—®é¢˜ï¼š
- [] è¯„ä¼°çš„ä»£ç åœ¨å“ªé‡Œï¼Ÿå’ŒåŸæ¥çš„è¯„ä¼°ä»£ç æœ‰ä»€ä¹ˆä¸åŒï¼Ÿï¼ˆè‡³å°‘ä»æ–‡ä»¶ç›®å½•ä¸Šé¢æˆ‘æ²¡æœ‰çœ‹å‡ºæœ‰ä»€ä¹ˆä¸åŒï¼‰




(base) wyren@DGX-A800:~/Knowledge-Editing-Benchmark$ grep -rn "teacher" .
Binary file ./LUFFY/data/valid.mmlu_pro.parquet matches
./EasyEdit/README.md:69:- 2025-03-04, ğŸŒŸğŸŒŸIn addition to the original token-level teacher-forcing paradigm for evaluation, EasyEdit has integrated a new evaluation method, following the paper titled "[The Mirage of Model Editing: Revisiting Evaluation in the Wild](https://arxiv.org/abs/2502.11177)". You can use this [script](https://github.com/zjunlp/EasyEdit/blob/main/examples/run_LLM_evaluation.py) to quickly launch this evaluation approach, which better aligns with real-world requirements. Special thanks to [@WanliYoung](https://github.com/WanliYoung) for contribution!
./EasyEdit/examples/CKnowEdit.md:331:Our evaluation metrics consist of the following four categories: `Edit Success(ES)`, `Generalization(Gen)`, `Portability(Por)` and `locality(Loc)`. However, unlike the traditional approach of using  token/logit-level metrics with teacher-forcing automatio for assessment, **CKnowEdit** employs a new evaluation method.
æ£€ç´¢å‘ç°åŸå§‹é¡¹ç›®ä¸­çš„ä»¥ä¸Šä¸¤å¤„æåˆ°äº†teacher-forcingå’Œæ–°çš„è¯„ä¼°æ–¹æ³•ã€‚æˆ‘è®¤ä¸ºæœ‰å¿…è¦å»ç ”ç©¶ä¸€ä¸‹ï¼Œä½†æ˜¯ç›®å‰çš„å½“åŠ¡ä¹‹æ€¥æ˜¯å…ˆææ¸…æ¥šteacher-forcingçš„ä»£ç æ˜¯æ€ä¹ˆä¸€å›äº‹ã€‚

***
12/25:è¿™å‘¨æ±‡æŠ¥å‰ï¼ŒæŠŠmethodsé‡Œçš„æ–¹æ³•åº”å¤ç°å°½å¤ç°ã€‚
- [] MEMOIR
- [] SAKE
- [] EditCoT
- [] MindBridge
- [] KGMET
- [] PRUNE
- [] SimIE
- [] RLEdit
- [] ELDER
- [] FastMEMIT
- [] UnKE 
- [] HSE
- [] EtCon

å…³äºå¤ç°ï¼Œè¦è®¾è®¡å¥½benchmenrkçš„è¾“å…¥è¾“å‡ºçš„ä»£ç å’Œè·¯å¾„ï¼Œæƒ³å¥½è¦ç»˜åˆ¶ä»€ä¹ˆè¡¨æ ¼

å› ä¸ºå¤ç°ä¸€å…±ç”¨åˆ°äº†ä¸‰ä¸ªæ¨¡å‹Llama2-7B-Chat , Llama-3.1-8B-Instruct , and Mistral-7B-Instructä¸Šå®ç°ï¼Œè€Œæˆ‘ç›®å‰åªæœ‰llama3.1-8B-Instructçš„æ¨¡å‹ï¼Œæ‰€ä»¥å…ˆç”¨è¿™ä¸ªæ¨¡å‹å¤ç°,å…ˆè·‘é€šæ•´ä¸ªæ¨¡å‹å†è¿‡æ¸¡åˆ°å…¶ä»–æ¨¡å‹ä¸Šã€‚

ç¬¬ä¸€æ­¥æ˜¯ç”¨MEMOIRå¯¹æ¨¡å‹ llama3.1-8b-instruct åˆ†åˆ«åœ¨ZsREå’ŒWikiData_counterfactä¸Šå¤ç°ã€‚
ææ¸…æ¥šbenchmarkçš„å®éªŒçš„è¾“å…¥å’Œè¾“å‡ºè·¯å¾„ï¼š
1. è®¡ç®—å››ä¸ªæŒ‡æ ‡çš„ä»£ç 
2. å››ä¸ªæŒ‡æ ‡çš„æ•°æ®åˆ†åˆ«åœ¨è¾“å‡ºçš„å“ªé‡Œæ‰¾åˆ°ï¼Ÿ
3. è¿è¡Œè®¡ç®—è¿™å››ä¸ªæŒ‡æ ‡çš„å®éªŒçš„å‘½ä»¤åœ¨å“ªé‡Œï¼Ÿæœ‰å“ªäº›è¾“å…¥è¾“å‡ºï¼Ÿè¾“å…¥çš„å‚æ•°åº”è¯¥æ€ä¹ˆè®¾è®¡ï¼Ÿ

æˆ‘åœ¨æƒ³æ˜¯ä¸æ˜¯å¾—å…ˆè·‘é€šä¸€ä¸ªbanchmarkå·²æœ‰çš„å®éªŒï¼Œåˆ†æä¸€ä¸‹è¾“å…¥å’Œè¾“å‡ºï¼Ÿä½†æ˜¯å°±æˆ‘ç›®å‰çš„äº†è§£ä¼¼ä¹ç»™å‡ºæ²¡æœ‰è¿™æ–¹é¢çš„å‘½ä»¤ï¼Ÿ

å‘½ä»¤è¡Œç”¨çš„å¯èƒ½å°±æ˜¯åŸæœ¬çš„å‘½ä»¤ã€‚

å­¦å§å¥½ï¼Œæˆ‘ç›®å‰æ•´ç†äº†25å¹´çŸ¥è¯†ç¼–è¾‘çš„æœ€è¿‘çš„ä¸€äº›å·¥ä½œï¼Œå‡†å¤‡åˆ†åˆ«ç”¨æˆ‘ä»¬çš„æ–¹æ³•è¯„ä¼°ä¸€ä¸‹ã€‚æˆ‘ç›®å‰è€ƒè™‘å…ˆå¤ç°ä¸€ä¸‹benchmarkå·¥ä½œçš„å®éªŒï¼Œçœ‹çœ‹è¾“å…¥è¾“å‡ºçš„è·¯å¾„å’Œæ•°æ®æ ¼å¼ï¼Œç„¶åå†ç”¨æˆ‘ä»¬çš„æ–¹æ³•è¯„ä¼°ä¸€ä¸‹æœ€æ–°çš„å·¥ä½œã€‚
ç›®å‰æˆ‘é‡åˆ°çš„é—®é¢˜æ˜¯ï¼šæˆ‘å‘ç°benchmarkçš„ä»£ç ä¸­æ²¡æœ‰æ‰¾åˆ°è¿è¡Œä¹‹å‰å®éªŒå¯¹åº”çš„å‘½ä»¤ï¼Œä»¥åŠå·²å®ç°çš„æ–¹æ³•å¯¹äºä¸åŒæ¨¡å‹çš„è¶…å‚æ•°æ–‡ä»¶å¥½åƒä¹Ÿæ²¡æœ‰æ”¾ä¸Šæ¥ï¼Œæƒ³é—®ä¸€ä¸‹è¿™æ–¹é¢çš„å…·ä½“å®ç°çš„ä»£ç å­¦å§æ–¹ä¾¿ç»™æˆ‘å˜›ï¼Ÿ

é—®å®Œäº†ï¼Œç°åœ¨æˆ‘è¦åšçš„æ˜¯å…ˆè·‘é€šè¿™å‡ ä¸ªå®éªŒæœ¬èº«ï¼

æ¨¡å‹è¯„ä¼°çš„ä¸»è¦å‘½ä»¤ï¼š
python run_LLM_evaluation.py \
--editing_method IKE \
--hparams_dir /mnt/geminisgceph1/geminicephfs/mmsearch-luban-universal/group_semantic/user_mylasong/EasyEdit/hparams/IKE/llama3.1-8b.yaml \
--data_dir /mnt/geminisgceph1/geminicephfs/mmsearch-luban-universal/group_semantic/user_mylasong/ModelEdit/EasyEdit_new/examples/dataset/zsre/ZsRE-test-all.json \
--train_data_path /mnt/geminisgceph1/geminicephfs/mmsearch-luban-universal/group_semantic/user_mylasong/ModelEdit/EasyEdit_new/examples/dataset/zsre/zsre_train_10000.json \
--datatype zsre \
--ds_size 1319 \
--start_index 0 \
--end_index 1319 \

ä¸‹ä¸€æ­¥è¦åšçš„ï¼š
1. ä¸‹è½½æ•°æ®é›†
2. è¯»æ‡‚ run_LLM_evaluation.py çš„ä»£ç ï¼Œå¦‚ä½•è®¡ç®—å„é¡¹æŒ‡æ ‡ï¼Ÿ
3. è¿è¡Œä¸€ä¸ªåŸæ¥çš„è¯„ä¼°å®éªŒ
4. è·‘é€šSAKEçš„å¤ç°ï¼ŒæŠŠSAKEé€‚åº”åˆ°æˆ‘ä»¬çš„è¯„ä¼°ä¸­ã€‚

ä¸‹è½½æ•°æ®é›†



è·‘ä¸‹é¢çš„ä¸€ä¸ªè¯„ä¼°å®éªŒï¼š
CUDA_VISIBLE_DEVICES=2 python /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/examples/run_LLM_evaluation.py \
    --editing_method IKE \
    --hparams_dir /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/hparams/IKE/llama3.1-8b.yaml \
    --data_dir /home/wyren/Knowledge-Editing-Benchmark/wyren/dataset/zsre/ZsRE-test-all.json \
    --output_dir /home/wyren/Knowledge-Editing-Benchmark/wyren/1outputs/benchmark
    --train_data_path /home/wyren/Knowledge-Editing-Benchmark/wyren/dataset/zsre/zsre_train_10000.json \
    --datatype zsre \
    --ds_size 10 \
    --start_index 0 \
    --end_index 10 \
    >/home/wyren/Knowledge-Editing-Benchmark/wyren/1outputs/benchmark/run_IKE_zsre_10.log 2>&1


## è¯»æ‡‚ run_LLM_evaluation.py ä»£ç :

è¶…å‚æ•°ï¼š
    å¿…éœ€å‚æ•°ï¼š
    --editing_methodï¼šç¼–è¾‘æ–¹æ³•ï¼ˆFTã€IKEã€ROMEã€MEMITã€LoRAç­‰ï¼‰
    --hparams_dirï¼šè¶…å‚æ•°é…ç½®æ–‡ä»¶ç›®å½•
    --data_dirï¼šæ•°æ®é›†ç›®å½•è·¯å¾„

    å¯é€‰å‚æ•°ï¼š
    --output_dirï¼šè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼š'./outputs'ï¼‰
    --ds_sizeï¼šæ•°æ®é›†å¤§å°é™åˆ¶ï¼ˆé»˜è®¤ï¼šNoneï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰
    --start_indexï¼šæ•°æ®èµ·å§‹ç´¢å¼•
    --end_indexï¼šæ•°æ®ç»“æŸç´¢å¼•
    --datatypeï¼šæ•°æ®ç±»å‹
        counterfactï¼šç»´åŸºç™¾ç§‘äº‹å®ä¿®æ­£æ•°æ®é›†
        recentï¼šè¿‘æœŸçŸ¥è¯†æ•°æ®é›†
        zsreï¼šZero-Shotå…³ç³»æŠ½å–æ•°æ®é›†
        wikibioï¼šç»´åŸºç™¾ç§‘äººç‰©ä¼ è®°æ•°æ®é›†
    --sequential_editï¼šæ˜¯å¦é¡ºåºç¼–è¾‘ï¼ˆå¤šä¸ªç¼–è¾‘è¿ç»­æ‰§è¡Œï¼‰
    --train_data_pathï¼šè®­ç»ƒæ•°æ®è·¯å¾„ï¼ˆIKEæ–¹æ³•éœ€è¦ï¼‰
    --evaluation_typeï¼šè¯„ä¼°ç±»å‹ï¼ˆé»˜è®¤ï¼š'LLM-judge'ï¼‰
    --api_keyï¼šAPIå¯†é’¥ï¼ˆç”¨äºLLM-as-a-Judgeè¯„ä¼°ï¼‰
    --pre_fileï¼šé¢„ç¼–è¾‘ç»“æœæ–‡ä»¶è·¯å¾„( æˆ‘ä¸æ¸…æ¥šä¸ºä»€ä¹ˆé»˜è®¤çš„è·¯å¾„çš„åç§°æ˜¯ qwen3_14b-pre-new.json ï¼Œå…ˆç›˜ä¸€ä¸‹ç”¨é€”å†è¯´ )

è¾“å‡ºçš„å†…å®¹ï¼š


è¾“å‡ºçš„è·¯å¾„ï¼š

æ•°æ®é›†çš„å¤„ç†ï¼š




æˆ‘ç°åœ¨æƒ³å…ˆè·‘é€šWISEçš„è¯„ä¼°ï¼Œç„¶åå†è·‘MEMIORçš„é€‚åº”
CUDA_VISIBLE_DEVICES=6 python /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/examples/run_LLM_evaluation.py \
    --editing_method WISE \
    --hparams_dir /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/hparams/WISE/llama3.1-8b.yaml \
    --data_dir /home/wyren/Knowledge-Editing-Benchmark/wyren/dataset/zsre/ZsRE-test-all.json \
    --output_dir /home/wyren/Knowledge-Editing-Benchmark/wyren/1outputs/benchmark \
    --train_data_path /home/wyren/Knowledge-Editing-Benchmark/wyren/dataset/zsre/zsre_train_10000.json \
    --datatype zsre \
    --ds_size 10 \
    --start_index 0 \
    --end_index 10 \
    --sequential_edit \
    >/home/wyren/Knowledge-Editing-Benchmark/wyren/1outputs/benchmark/run_WISE_zsre_10_rewrite_portability.log 2>&1

è¿™ä¸ªè·‘é€šäº†ï¼Œç»“æœåœ¨
/home/wyren/Knowledge-Editing-Benchmark/wyren/1outputs/benchmark/run_WISE_zsre_10.log
å’Œ
/home/wyren/Knowledge-Editing-Benchmark/wyren/1outputs/benchmark/zsre_0e9e39f249a16976918f6564b8830bc894c89659_WISE_N=10_Sequential=True_2025-12-27_16-44-23.json
ä½†æ˜¯é—®é¢˜æ˜¯è¿™ä¸ªç»“æœé‡Œé¢å¹¶æ²¡æœ‰å‡ºç°æˆ‘æœŸæœ›çš„4ä¸ªæŒ‡æ ‡ï¼Œåè€Œè¿˜å­˜åœ¨ä¸€äº›æˆ‘ç†è§£ä¸äº†çš„å­—æ®µï¼Œæ¯”å¦‚è¯´gen_contentï¼Œä½†æ˜¯æˆ‘é€šè¿‡grepæ— æ³•å®šä½è¿™äº›å­—æ®µæ˜¯æ€ä¹ˆç”Ÿæˆçš„ï¼Ÿï¼Ÿ
- [] æ‰“ç®—å…ˆç­‰dkèµ·æ¥å†é—®ä»–

ç›®å‰çš„æ€è·¯æ˜¯å…ˆå»å®ç°1SAKEå’Œ2EditCoT/3MendBridgeçš„å¤ç°






æˆ‘æ„è¯†åˆ°ä¸¤ç‚¹ï¼š
1. è·‘ä»£ç å‰è¦å…ˆçœ‹æ‡‚ä»£ç 
2. clear.log æ˜¯å†™ç»™è‡ªå·±çš„ï¼Œmarkdownæ˜¯å†™ç»™åˆ«äººçš„ï¼Œè¦æƒ³æ¸…æ¥šä»€ä¹ˆæ˜¯è¦å±•ç¤ºç»™åˆ«äººçš„ 

å¤ç°SAKE










***çª—å£å®‰æ’
wyren
    /home/wyren/Knowledge-Editing-Benchmark/wyren/clear.log å®éªŒæ—¥å¿—
    /home/wyren/Knowledge-Editing-Benchmark/wyren/notebooks/reproduce.ipynb å¤ç°ç»“æœå‘ˆç°
å¤ç°
    1SAKEå¤ç°
        /home/wyren/Knowledge-Editing-Benchmark/methods/1SAKE/README.md
        åŸºæœ¬ä¿¡æ¯ï¼š
            

        


å„é¡¹ç›®çš„é‡è¦æ–‡ä»¶
    benchmarkä¸­çš„é‡è¦æ–‡ä»¶
        /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/examples/run_LLM_evaluation.py è¿è¡Œè¯„ä¼°çš„ä¸»è¦ä»£ç 
        /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/examples/run_LLM_evaluation.sh è¿è¡Œè¯„ä¼°çš„å‘½ä»¤
        /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/easyeditor/editors/editor.py ç¼–è¾‘å™¨åŸºç±»
        /home/wyren/Knowledge-Editing-Benchmark/EasyEdit/easyeditor/evaluate/evaluate.py è¯„ä¼°åŸºç±»

    0MEMOIRä¸­çš„é‡è¦æ–‡ä»¶
        1

    1SAKEä¸­çš„é‡è¦æ–‡ä»¶
        /home/wyren/Knowledge-Editing-Benchmark/methods/1SAKE/README.md
        1

    2EditCoTä¸­çš„é‡è¦æ–‡ä»¶
        1

    3MindBridgeä¸­çš„é‡è¦æ–‡ä»¶
        1

    4KGMETä¸­çš„é‡è¦æ–‡ä»¶
        1

    5PRUNEä¸­çš„é‡è¦æ–‡ä»¶
        1

    6SimIEä¸­çš„é‡è¦æ–‡ä»¶
        1

    7RLEditä¸­çš„é‡è¦æ–‡ä»¶
        1

    8ELDERä¸­çš„é‡è¦æ–‡ä»¶
        1

    9FastMEMITä¸­çš„é‡è¦æ–‡ä»¶
        1

    10UnKEä¸­çš„é‡è¦æ–‡ä»¶
        1

    11HSEä¸­çš„é‡è¦æ–‡ä»¶
        1

    12EtConä¸­çš„é‡è¦æ–‡ä»¶
    1
















